{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3862a56a-a333-4a5d-a708-018a0a5d8f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimji\\AppData\\Local\\Temp\\ipykernel_13200\\2284917278.py:14: FutureWarning: set_caching_enabled is deprecated and will be removed in the next major version of datasets. Use datasets.enable_caching() or datasets.disable_caching() instead. This function will be removed in a future version of datasets.\n",
      "  set_caching_enabled(False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric,Dataset,concatenate_datasets,set_caching_enabled, ClassLabel\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import json\n",
    "from transformers import Wav2Vec2CTCTokenizer,Wav2Vec2ForCTC,Wav2Vec2Processor,Trainer,TrainingArguments,Wav2Vec2FeatureExtractor\n",
    "\n",
    "import re\n",
    "set_caching_enabled(False)\n",
    "\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['WANDB_DISABLED '] = 'True'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ec7fb3-db70-4eea-aae7-19d5deeb9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import transformers\n",
    "transformers.logging.get_verbosity = lambda: logging.NOTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a8408e-5648-49bf-8f2d-d453dbb90941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 1.12.1+cu116\n",
      "CUDA 버전: 11.6\n",
      "CUDA 사용 가능: True\n",
      "cuDNN 사용 가능: True\n",
      "GPU 수: 1\n",
      "GPU 0 이름: NVIDIA GeForce RTX 2060\n",
      "cuda\n",
      "cuDNN 버전: 8302\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "print(\"cuDNN 사용 가능:\", torch.backends.cudnn.enabled)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 수:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i} 이름:\", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"GPU를 찾을 수 없습니다. CPU를 사용합니다.\")\n",
    "\n",
    "print(device)\n",
    "print(\"cuDNN 버전:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d5ec2a-e60a-41b3-aa0d-3f7abf535437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.logging.get_verbosity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6836cb22-7135-4bc8-981e-6cc5b4c3a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "datasets.logging.get_verbosity = lambda: logging.NOTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe257fb3-b067-4c90-9da0-e93b0e5a6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\".train.csv\")\n",
    "df[\"votes\"] = df[\"up_votes\"]-df[\"down_votes\"]\n",
    "\n",
    "#Add audio path and renaming columns\n",
    "df[\"path\"] = \"../input/wolof-asr/Noise Removed/tmp/WOLOF_ASR_dataset/noise_remove/\"+df[\"ID\"]+\".wav\"\n",
    "df.rename(columns = {'transcription':'sentence'}, inplace = True)\n",
    "\n",
    "train,test = train_test_split(df, test_size=0.005, random_state=42)\n",
    "common_voice_train_1 = Dataset.from_pandas(train[3000:])\n",
    "common_voice_train_2 = Dataset.from_pandas(train[0:3000])\n",
    "\n",
    "common_voice_test = Dataset.from_pandas(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "fakeaudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
